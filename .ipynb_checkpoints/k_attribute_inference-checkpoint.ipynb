{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9860c28-8e1b-46b6-8666-965a5eff59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Running attribute inference attacks on the Nursery data\n",
    "# \n",
    "# In this tutorial we will show how to run both black-box and white-box inference attacks. This will be demonstrated on the Nursery dataset (original dataset can be found here: https://archive.ics.uci.edu/ml/datasets/nursery).\n",
    "# \n",
    "# ## Preliminaries\n",
    "# \n",
    "# In the case of the nursery dataset, the sensitive feature we want to infer is the 'social' feature. In the original dataset this is a categorical feature with 3 possible values. To make the attack more successful, we reduced this to two possible feature values by assigning the original value 'problematic' the new value 1, and the other original values were assigned the new value 0.\n",
    "# \n",
    "# We have also already preprocessed the dataset such that all categorical features are one-hot encoded, and the data was scaled using sklearn's StandardScaler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f0df555-13e0-4df4-8036-2bc91cc13099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab3ab8c-fab4-4b31-ab8d-1d7449d98dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nursery(test_set=0.5, transform_social=True, random_state=42):\n",
    "    \"\"\"\n",
    "    Load and preprocess the nursery dataset.\n",
    "    \n",
    "    :param test_set: Proportion of the dataset to include in the test split\n",
    "    :param transform_social: If True, transform the social feature to binary (0,1)\n",
    "    :param random_state: Random seed for reproducibility\n",
    "    :return: (x_train, y_train), (x_test, y_test), feature_names, social_values\n",
    "    \"\"\"\n",
    "    # Download the dataset if it doesn't exist\n",
    "    dataset_path = 'nursery.data'\n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(\"Downloading nursery dataset...\")\n",
    "        url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/nursery/nursery.data'\n",
    "        urlretrieve(url, dataset_path)\n",
    "    \n",
    "    # Column names from the dataset description\n",
    "    column_names = ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health', 'class']\n",
    "    \n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(dataset_path, header=None, names=column_names)\n",
    "    \n",
    "    # Transform the social feature to binary if required\n",
    "    social_values = None\n",
    "    if transform_social:\n",
    "        # Map 'problematic' to 1, everything else to 0\n",
    "        social_mapping = {'problematic': 1, 'slightly_prob': 0, 'nonprob': 0}\n",
    "        data['social'] = data['social'].map(social_mapping)\n",
    "        social_values = [0, 1]  # The possible values after transformation\n",
    "    \n",
    "    # Extract the target variable (class)\n",
    "    y = data['class']\n",
    "    X = data.drop('class', axis=1)\n",
    "    \n",
    "    # Get the social feature for later use\n",
    "    social_feature = X['social']\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    categorical_features = X.columns\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    X_encoded = encoder.fit_transform(X)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_encoded)\n",
    "    \n",
    "    # Split the dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_set, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Get feature names after one-hot encoding\n",
    "    feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    # Find the index of the social feature in the transformed dataset\n",
    "    social_feature_indices = [i for i, name in enumerate(feature_names) if name.startswith('social_')]\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test), feature_names, social_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b91f513-d7b8-4b23-b569-072cb194fb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nursery dataset...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (x_train, y_train), (x_test, y_test), feature_names, social_indices \u001b[38;5;241m=\u001b[39m \u001b[43mload_nursery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_social\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 40\u001b[0m, in \u001b[0;36mload_nursery\u001b[0;34m(test_set, transform_social, random_state)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# One-hot encode categorical features\u001b[39;00m\n\u001b[1;32m     39\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m---> 40\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m X_encoded \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Scale the features\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test), feature_names, social_indices = load_nursery(test_set=0.5, transform_social=True)\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Testing data shape: {x_test.shape}\")\n",
    "print(f\"Social feature indices: {social_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59900ae5-0f1a-40f9-b28e-7aa739b656c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
